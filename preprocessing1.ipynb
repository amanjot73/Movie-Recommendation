{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be8df73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMported Successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "chunk_size = 200000\n",
    "chunks = pd.read_csv('title.basics.tsv',sep='\\t',na_values='\\\\N',dtype=str,chunksize=chunk_size)\n",
    "movie_chunks = []\n",
    "for chunk in chunks:\n",
    "    movie = chunk[(chunk['titleType']=='movie') & (chunk['runtimeMinutes'].notna())& (chunk['genres'].notna())][['tconst','primaryTitle','runtimeMinutes','genres']]\n",
    "\n",
    "    movie_chunks.append(movie)\n",
    "movie = pd.concat(movie_chunks,ignore_index=True)\n",
    "print(\"IMported Successfully\")\n",
    "movie.to_csv(\"updated_title.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c7c4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst                   primaryTitle runtimeMinutes  \\\n",
      "0  tt0000009                     Miss Jerry             45   \n",
      "1  tt0000147  The Corbett-Fitzsimmons Fight            100   \n",
      "2  tt0000335          Soldiers of the Cross             40   \n",
      "3  tt0000574    The Story of the Kelly Gang             70   \n",
      "4  tt0000591               The Prodigal Son             90   \n",
      "\n",
      "                       genres  \n",
      "0                     Romance  \n",
      "1      Documentary,News,Sport  \n",
      "2             Biography,Drama  \n",
      "3  Action,Adventure,Biography  \n",
      "4                       Drama  \n"
     ]
    }
   ],
   "source": [
    "print(movie.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4273cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.to_csv(\"updated_title.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75907494",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 200000\n",
    "chunks = pd.read_csv('title.ratings.tsv',sep='\\t',na_values='\\\\N',dtype=str,chunksize=chunk_size)\n",
    "main = []\n",
    "for chunk in chunks:\n",
    "    movie = chunk[['tconst','averageRating']]\n",
    "    main.append(movie)\n",
    "m2 = pd.concat(main,ignore_index=True)\n",
    "m2.to_csv('updated_rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14573fce",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Step 2: Extract just those columns line by line (super low RAM!)\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(input_file, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_in, \u001b[38;5;28mopen\u001b[39m(output_file, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_out:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf_in\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:322\u001b[39m, in \u001b[36mBufferedIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[32m    318\u001b[39m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    323\u001b[39m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[32m    324\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.buffer + \u001b[38;5;28minput\u001b[39m\n\u001b[32m    325\u001b[39m     (result, consumed) = \u001b[38;5;28mself\u001b[39m._buffer_decode(data, \u001b[38;5;28mself\u001b[39m.errors, final)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "input_file = 'title.akas.tsv'\n",
    "output_file = 'akas_tiny.tsv'\n",
    "\n",
    "wanted_cols = ['titleId', 'language']  # Adjust for other files as needed\n",
    "\n",
    "# Step 1: Find column index mapping\n",
    "with open(input_file, 'r', encoding='utf-8') as f:\n",
    "    header = f.readline().strip().split('\\t')\n",
    "col_idx = [header.index(col) for col in wanted_cols]\n",
    "\n",
    "# Step 2: Extract just those columns line by line (super low RAM!)\n",
    "with open(input_file, 'r', encoding='utf-8') as f_in, open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "    for line in f_in:\n",
    "        fields = line.strip().split('\\t')\n",
    "        try:\n",
    "            selected = [fields[i] for i in col_idx]\n",
    "        except IndexError:\n",
    "            continue  # skip broken/malformed lines\n",
    "        f_out.write('\\t'.join(selected) + '\\n')\n",
    "\n",
    "print(\"Columns written to\", output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "012bf526",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43moutput_file\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'output_file' is not defined"
     ]
    }
   ],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e12c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([',titleId', 'language'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pycountry\n",
    "import pandas as pd\n",
    "def code_to_name(code):\n",
    "    try:\n",
    "        return pycountry.languages.get(alpha_2=code).name\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def codes_to_names(codes):\n",
    "    return ', '.join([code_to_name(c.strip()) for c in str(codes).split(',') if c])\n",
    "df = pd.read_csv('updated_language.csv', sep='\\t')\n",
    "print(df.columns)  # You want ['titleId', 'language']\n",
    "df['language_name'] = df['language'].apply(codes_to_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65838624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be928d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['language_name'] != 'Unknown']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68c959b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 191\n"
     ]
    }
   ],
   "source": [
    "filtered_df = filtered_df.drop(columns=['language'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3eec8f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35761958, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3290f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('updated_languages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e73835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "chunk_size = 200000\n",
    "chunks = pd.read_csv('name.basics.tsv',sep='\\t',na_values='\\\\N',dtype=str,chunksize=chunk_size)\n",
    "main = []\n",
    "for chunk in chunks:\n",
    "    movie = chunk[['nconst','primaryName','knownForTitles','primaryProfession']]\n",
    "    main.append(movie)\n",
    "d = pd.concat(main,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e0436b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nconst</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>knownForTitles</th>\n",
       "      <th>primaryProfession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm0000001</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>tt0072308,tt0050419,tt0027125,tt0025164</td>\n",
       "      <td>actor,miscellaneous,producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0000002</td>\n",
       "      <td>Lauren Bacall</td>\n",
       "      <td>tt0037382,tt0075213,tt0038355,tt0117057</td>\n",
       "      <td>actress,soundtrack,archive_footage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0000003</td>\n",
       "      <td>Brigitte Bardot</td>\n",
       "      <td>tt0057345,tt0049189,tt0056404,tt0054452</td>\n",
       "      <td>actress,music_department,producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0000004</td>\n",
       "      <td>John Belushi</td>\n",
       "      <td>tt0072562,tt0077975,tt0080455,tt0078723</td>\n",
       "      <td>actor,writer,music_department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0000005</td>\n",
       "      <td>Ingmar Bergman</td>\n",
       "      <td>tt0050986,tt0069467,tt0083922,tt0050976</td>\n",
       "      <td>writer,director,actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nm0000006</td>\n",
       "      <td>Ingrid Bergman</td>\n",
       "      <td>tt0034583,tt0038109,tt0036855,tt0038787</td>\n",
       "      <td>actress,producer,soundtrack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nm0000007</td>\n",
       "      <td>Humphrey Bogart</td>\n",
       "      <td>tt0034583,tt0043265,tt0037382,tt0033870</td>\n",
       "      <td>actor,producer,miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nm0000008</td>\n",
       "      <td>Marlon Brando</td>\n",
       "      <td>tt0078788,tt0068646,tt0047296,tt0070849</td>\n",
       "      <td>actor,director,writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nm0000009</td>\n",
       "      <td>Richard Burton</td>\n",
       "      <td>tt0061184,tt0087803,tt0057877,tt0059749</td>\n",
       "      <td>actor,producer,director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nm0000010</td>\n",
       "      <td>James Cagney</td>\n",
       "      <td>tt0029870,tt0031867,tt0042041,tt0034236</td>\n",
       "      <td>actor,director,producer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nconst      primaryName                           knownForTitles  \\\n",
       "0  nm0000001     Fred Astaire  tt0072308,tt0050419,tt0027125,tt0025164   \n",
       "1  nm0000002    Lauren Bacall  tt0037382,tt0075213,tt0038355,tt0117057   \n",
       "2  nm0000003  Brigitte Bardot  tt0057345,tt0049189,tt0056404,tt0054452   \n",
       "3  nm0000004     John Belushi  tt0072562,tt0077975,tt0080455,tt0078723   \n",
       "4  nm0000005   Ingmar Bergman  tt0050986,tt0069467,tt0083922,tt0050976   \n",
       "5  nm0000006   Ingrid Bergman  tt0034583,tt0038109,tt0036855,tt0038787   \n",
       "6  nm0000007  Humphrey Bogart  tt0034583,tt0043265,tt0037382,tt0033870   \n",
       "7  nm0000008    Marlon Brando  tt0078788,tt0068646,tt0047296,tt0070849   \n",
       "8  nm0000009   Richard Burton  tt0061184,tt0087803,tt0057877,tt0059749   \n",
       "9  nm0000010     James Cagney  tt0029870,tt0031867,tt0042041,tt0034236   \n",
       "\n",
       "                    primaryProfession  \n",
       "0        actor,miscellaneous,producer  \n",
       "1  actress,soundtrack,archive_footage  \n",
       "2   actress,music_department,producer  \n",
       "3       actor,writer,music_department  \n",
       "4               writer,director,actor  \n",
       "5         actress,producer,soundtrack  \n",
       "6        actor,producer,miscellaneous  \n",
       "7               actor,director,writer  \n",
       "8             actor,producer,director  \n",
       "9             actor,director,producer  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0063f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv('updated_names_info.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
